#!/usr/bin/env python3
"""
Z-Library æ‰¹é‡ä¸‹è¼‰è…³æœ¬
æ‰¹é‡ä¸‹è¼‰å¤šæœ¬æ›¸ç±ï¼Œå„ªå…ˆ PDF æ ¼å¼

ç”¨æ³•ï¼š
    python3 batch_download.py --urls urls.json --output ~/Z-Library
    python3 batch_download.py --url "https://z-lib.fm/book/123" --output ~/Z-Library
"""

import asyncio
import json
import argparse
from pathlib import Path
from playwright.async_api import async_playwright

# é…ç½®
CONFIG_DIR = Path.home() / ".zlibrary"
STORAGE_STATE = CONFIG_DIR / "storage_state.json"
DEFAULT_OUTPUT_DIR = Path.home() / "Desktop" / "Z-Library"
DELAY_BETWEEN_DOWNLOADS = 5  # ç§’
MAX_RETRIES = 3


async def download_single_book(page, url: str, output_dir: Path, retry_count: int = 0) -> Path | None:
    """
    ä¸‹è¼‰å–®æœ¬æ›¸ç±
    
    Args:
        page: Playwright page ç‰©ä»¶
        url: æ›¸ç±é é¢ URL
        output_dir: ä¸‹è¼‰ç›®éŒ„
        retry_count: ç•¶å‰é‡è©¦æ¬¡æ•¸
        
    Returns:
        ä¸‹è¼‰çš„æª”æ¡ˆè·¯å¾‘ï¼Œå¤±æ•—å‰‡è¿”å› None
    """
    
    download_path = None
    
    async def handle_download(download):
        nonlocal download_path
        suggested_filename = download.suggested_filename
        # è§£ç¢¼æª”åï¼ˆé¿å…äº‚ç¢¼ï¼‰
        try:
            from urllib.parse import unquote
            suggested_filename = unquote(suggested_filename)
        except:
            pass
            
        download_path = output_dir / suggested_filename
        await download.save_as(download_path)
        print(f"    ğŸ’¾ å·²å„²å­˜: {download_path.name}")
    
    # ç§»é™¤èˆŠçš„ listener ä»¥å…é‡è¤‡
    try:
        page.remove_listener('download', handle_download)
    except:
        pass
    page.on('download', handle_download)
    
    try:
        print(f"  ğŸ“– è¨ªå•æ›¸ç±é é¢...")
        await page.goto(url, wait_until='domcontentloaded', timeout=60000)
        await asyncio.sleep(5)
        
        # å˜—è©¦æ·»åŠ åˆ°æˆ‘çš„åœ–æ›¸é¤¨
        try:
            add_lib_btn = await page.query_selector('.book-details-button:has-text("Add to My Library"), .book-details-button:has-text("æ·»åŠ åˆ°æˆ‘çš„å›¾ä¹¦é¦†"), .book-details-button:has-text("æ·»åŠ åˆ°æˆ‘çš„åœ–æ›¸é¤¨")')
            if add_lib_btn:
                await add_lib_btn.click()
                print("    ğŸ“š å·²æ·»åŠ åˆ°æˆ‘çš„åœ–æ›¸é¤¨")
            else:
                # æª¢æŸ¥æ˜¯å¦å·²ç¶“æ·»åŠ  (æŒ‰éˆ•æ–‡å­—å¯èƒ½è®Šæˆ "Remove from My Library" æˆ–é¡ä¼¼)
                pass
        except Exception as e:
            print(f"    âš ï¸ æ·»åŠ åˆ°åœ–æ›¸é¤¨å¤±æ•—: {e}")
        
        # 1. å˜—è©¦ç›´æ¥ä¸‹è¼‰ PDF
        pdf_link = await page.query_selector('a[href*="/dl/"][href*="pdf"], a.addDownloadedBook[href*="pdf"]')
        
        if pdf_link:
            print(f"    âœ… æ‰¾åˆ° PDF ä¸‹è¼‰é€£çµ")
            await pdf_link.click()
        else:
            # 2. å˜—è©¦é€éä¸‹æ‹‰é¸å–®è½‰æ›
            print(f"    ğŸ” æª¢æŸ¥æ ¼å¼é¸é …...")
            format_btn = await page.query_selector('#btnCheckOtherFormats, .dlDropdownBtn, [class*="book-details-button-toggle"]')
            
            if format_btn:
                await format_btn.click()
                await asyncio.sleep(2)
                
                # æ‰¾ PDF è½‰æ›é¸é …
                convert_link = await page.query_selector('a[data-convert_to="pdf"], a[href*="convertedTo=pdf"], .dropdown-menu a:has-text("PDF")')
                
                if convert_link:
                    print(f"    ğŸ”„ å•Ÿå‹• PDF è½‰æ›...")
                    await convert_link.click()
                    
                    # ç­‰å¾…è½‰æ›å®Œæˆ
                    print(f"    â³ ç­‰å¾…è½‰æ›ä¸­ (ç´„éœ€ 30-60 ç§’)...")
                    for i in range(60):
                        # æª¢æŸ¥æ˜¯å¦å‡ºç¾è½‰æ›å¾Œçš„ä¸‹è¼‰é€£çµ
                        dl_link = await page.query_selector('a[href*="/dl/"][href*="convertedTo=pdf"]')
                        if dl_link and await dl_link.is_visible():
                            print(f"    âœ… è½‰æ›å®Œæˆï¼Œé–‹å§‹ä¸‹è¼‰")
                            await dl_link.click()
                            break
                        
                        # æª¢æŸ¥æ˜¯å¦å·²ç¶“é–‹å§‹ä¸‹è¼‰ (æœ‰äº›è½‰æ›æœƒè‡ªå‹•è§¸ç™¼ä¸‹è¼‰)
                        if download_path:
                            break
                            
                        await asyncio.sleep(1)
                else:
                    print(f"    âš ï¸ ç„¡ PDF é¸é …ï¼Œå˜—è©¦ä¸‹è¼‰é è¨­æ ¼å¼ (EPUB)")
                    dl_link = await page.query_selector('a[href*="/dl/"], .addDownloadedBook')
                    if dl_link:
                        await dl_link.click()
            else:
                # 3. ç„¡ä¸‹æ‹‰é¸å–®ï¼Œç›´æ¥ä¸‹è¼‰
                print(f"    âš ï¸ ç„¡æ ¼å¼é¸é …ï¼Œç›´æ¥ä¸‹è¼‰")
                dl_link = await page.query_selector('a[href*="/dl/"], .addDownloadedBook')
                if dl_link:
                    await dl_link.click()

        # ç­‰å¾…ä¸‹è¼‰å®Œæˆ
        for i in range(120):
            if download_path and download_path.exists():
                return download_path
            await asyncio.sleep(1)
            if i % 10 == 0 and i > 0:
                print(f"    â³ ä¸‹è¼‰ä¸­... {i}ç§’")
        
        print(f"    âš ï¸ ä¸‹è¼‰è¶…æ™‚æˆ–å¤±æ•—")
        
    except Exception as e:
        print(f"    âŒ ä¸‹è¼‰éŒ¯èª¤: {e}")
        
        # é‡è©¦é‚è¼¯
        if retry_count < MAX_RETRIES:
            print(f"    ğŸ”„ é‡è©¦ä¸­... ({retry_count + 1}/{MAX_RETRIES})")
            await asyncio.sleep(5)
            return await download_single_book(page, url, output_dir, retry_count + 1)
    
    return None


async def batch_download(urls: list[str], output_dir: Path) -> list[dict]:
    """
    æ‰¹é‡ä¸‹è¼‰æ›¸ç±
    
    Args:
        urls: æ›¸ç±é é¢ URL æ¸…å–®
        output_dir: ä¸‹è¼‰ç›®éŒ„
        
    Returns:
        ä¸‹è¼‰çµæœæ¸…å–®
    """
    
    # è¼‰å…¥é…ç½®
    config_path = CONFIG_DIR / "config.yaml"
    if config_path.exists():
        import yaml
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
    else:
        config = {
            'download': {
                'output_dir': str(DEFAULT_OUTPUT_DIR),
                'books_subdir': 'Books',
                'reports_subdir': 'Reports',
                'delay_between_books': 5
            }
        }

    if not STORAGE_STATE.exists():
        print("âŒ æœªæ‰¾åˆ° Z-Library ç™»å…¥ç‹€æ…‹")
        print("ğŸ’¡ è«‹å…ˆåŸ·è¡Œ: python3 scripts/login.py")
        return []
    
    # è¨­å®šè¼¸å‡ºç›®éŒ„
    # å„ªå…ˆä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨é…ç½®æª”ï¼Œæœ€å¾Œæ˜¯é è¨­å€¼
    if output_dir != DEFAULT_OUTPUT_DIR: # åˆ¤æ–·æ˜¯å¦ç‚ºå‘½ä»¤è¡Œé è¨­å€¼
        base_dir = output_dir
    else:
        base_dir = Path(config['download']['output_dir']).expanduser()
    
    books_dir = base_dir / config['download'].get('books_subdir', 'Books')
    books_dir.mkdir(parents=True, exist_ok=True)
    
    results = []
    
    async with async_playwright() as p:
        print(f"ğŸ“¥ é–‹å§‹æ‰¹é‡ä¸‹è¼‰ {len(urls)} æœ¬æ›¸ç±")
        print(f"ğŸ“ ä¸‹è¼‰ç›®éŒ„: {books_dir}")
        print("=" * 50)
        
        # å•Ÿå‹•ç€è¦½å™¨
        browser = await p.chromium.launch(headless=False)  # ä½¿ç”¨æœ‰é ­æ¨¡å¼ä»¥ä¾¿è™•ç†é©—è­‰
        context = await browser.new_context(
            storage_state=str(STORAGE_STATE),
            accept_downloads=True
        )
        page = await context.new_page()
        page.set_default_timeout(60000)
        
        for i, book_data in enumerate(urls):
            url = book_data.get('url')
            if not url:
                print(f"\n[{i+1}/{len(urls)}] âš ï¸ è·³éç„¡æ•ˆçš„æ›¸ç±è³‡æ–™: {book_data}")
                results.append({
                    "index": i + 1,
                    "url": None,
                    "success": False,
                    "path": None,
                    "error": "URL missing"
                })
                continue

            print(f"\n[{i+1}/{len(urls)}] ä¸‹è¼‰æ›¸ç±...")
            print(f"  ğŸ”— {url[:60]}...")
            
            downloaded_path = await download_single_book(page, url, books_dir)
            
            result = {
                "index": i + 1,
                "url": url,
                "success": downloaded_path is not None,
                "path": str(downloaded_path) if downloaded_path else None
            }
            results.append(result)
            
            if downloaded_path:
                print(f"  âœ… ä¸‹è¼‰æˆåŠŸ: {downloaded_path.name}")
            else:
                print(f"  âŒ ä¸‹è¼‰å¤±æ•—")
            
            # æ›¸ç±é–“å»¶é²ï¼ˆé¿å…è§¸ç™¼é™é€Ÿï¼‰
            if i < len(urls) - 1:
                delay = config['download']['delay_between_books']
                print(f"  â³ ç­‰å¾… {delay} ç§’...")
                await asyncio.sleep(delay)
        
        await browser.close()
    
    # çµ±è¨ˆçµæœ
    success_count = sum(1 for r in results if r['success'])
    print("\n" + "=" * 50)
    print(f"ğŸ“Š ä¸‹è¼‰å®Œæˆ: {success_count}/{len(urls)} æœ¬æˆåŠŸ")
    
    return results


def main():
    parser = argparse.ArgumentParser(description="Z-Library æ‰¹é‡ä¸‹è¼‰å·¥å…·")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--urls", help="JSON æª”æ¡ˆï¼ŒåŒ…å«æ›¸ç± URL æ¸…å–®")
    group.add_argument("--url", help="å–®ä¸€æ›¸ç± URL")
    parser.add_argument("--output", "-o", default=str(DEFAULT_OUTPUT_DIR), help=f"ä¸‹è¼‰ç›®éŒ„ (é è¨­: {DEFAULT_OUTPUT_DIR})")
    
    args = parser.parse_args()
    
    # è§£æ URL æ¸…å–®
    if args.urls:
        with open(args.urls, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # æ”¯æ´å…©ç¨®æ ¼å¼ï¼šç´” URL æ¸…å–®æˆ–åŒ…å« url æ¬„ä½çš„ç‰©ä»¶æ¸…å–®
            if isinstance(data, list):
                if data and isinstance(data[0], dict):
                    urls = data # ç›´æ¥å‚³éå­—å…¸åˆ—è¡¨
                else:
                    # å¦‚æœæ˜¯å­—ä¸²åˆ—è¡¨ï¼ŒåŒ…è£æˆå­—å…¸
                    urls = [{'url': url} for url in data]
            else:
                urls = [data] if isinstance(data, dict) else [{'url': data}]
    else:
        urls = [{'url': args.url}]
    
    output_dir = Path(args.output).expanduser()
    
    # åŸ·è¡Œä¸‹è¼‰
    results = asyncio.run(batch_download(urls, output_dir))
    
    # è¼¸å‡ºçµæœæ‘˜è¦
    print("\nğŸ“‹ ä¸‹è¼‰çµæœ:")
    for r in results:
        status = "âœ…" if r['success'] else "âŒ"
        filename = Path(r['path']).name if r['path'] else "N/A"
        print(f"  {status} [{r['index']}] {filename}")


if __name__ == "__main__":
    main()
